{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Meta Bayes module\n",
                "\n",
                "This is a short preview of the Meta Bayes module.\n",
                "Meta Bayes strives to compute the optimal prior for a set of tasks.\n",
                "\n",
                "It relies on the penalized regression formulation of the inner PAC-Bayesian algorithm:\n",
                "\n",
                "$$\\hat\\theta =\\arg\\inf_\\theta \\tilde{S}_i(\\theta, \\theta_0) := \\pi(\\theta)[S_i] + \\lambda \\text{KL}(\\pi(\\theta), \\pi(\\theta_0))$$ \n",
                "\n",
                "Noting $A_i(\\theta_0)$ the solution of the task $i$ using prior $\\theta_0$, the meta score can be written as\n",
                "\n",
                "$$\\sum S_{i}^{meta}(\\theta_0) = \\tilde{S}_i(A_i(\\theta_0), \\theta_0).$$\n",
                "\n",
                "The meta learning algorithm uses gradient descent to minimize the meta_score, relying on \n",
                "\n",
                "$$\\nabla S_i^{meta} = \\lambda \\nabla F_i $$ \n",
                "where $F_i(\\theta) = \\text{KL}(\\pi(A_i(\\theta_0)), \\pi(\\theta))$."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from surpbayes.meta_bayes import Task, MetaLearningEnv\n",
                "from surpbayes.proba import GaussianMap, TensorizedGaussianMap, BlockDiagGaussMap\n",
                "import numpy as np\n",
                "import numba as nb"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Choose dimension/Number of tasks\n",
                "d = 4\n",
                "n_tasks = 100\n",
                "\n",
                "# Generate tasks\n",
                "def make_score(x):\n",
                "#     @nb.njit(nb.float64[:](nb.float64[:,:]))\n",
                "    def score(xs):\n",
                "        return ((x - xs) ** 2).sum(-1)\n",
                "\n",
                "    return score\n",
                "\n",
                "\n",
                "x0 = 0.5 + np.random.normal(0, 0.2, d)\n",
                "# x0[[1, 3]] = x0[[0, 2]]\n",
                "x_middles = x0 + np.random.normal(0, 0.1, (n_tasks, d))\n",
                "\n",
                "list_task = [\n",
                "    Task(make_score(x_mid), temperature=0.1, vectorized=True) for x_mid in x_middles\n",
                "]\n",
                "\n",
                "task_trains = list_task[::2]\n",
                "task_test = list_task[1::2]\n",
                "\n",
                "# Define distribution family\n",
                "proba_map = GaussianMap(d)\n",
                "# proba_map = BlockDiagGaussMap([[0,1], [2,3]])\n",
                "# proba_map = TensorizedGaussianMap(d)\n",
                "\n",
                "# Define Meta Learning Environnement\n",
                "mlearn = MetaLearningEnv(\n",
                "    proba_map,\n",
                "    list_task=task_trains,\n",
                "    per_step=50,\n",
                "    chain_length=2,\n",
                "    kl_max=100.0,\n",
                "    silent=True,\n",
                "    n_max_eval=75\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "x_middles = x0 + np.random.normal(0, 0.1, (10, d))\n",
                "\n",
                "test_tasks = [\n",
                "    Task(make_score(x_mid), temperature=0.1, vectorized=True) for x_mid in x_middles\n",
                "]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "mlearn.meta_learn(epochs=1, eta=20.0, kl_max=1.0)\n",
                "mlearn.hyperparams.update({\"per_step\":10**5, \"chain_length\":1})\n",
                "mlearn.meta_learn(epochs=20, eta=20.0, kl_max=1.0)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import shutil\n",
                "\n",
                "shutil.rmtree(\"my_learning_env\")\n",
                "mlearn.save(\"my_learning_env\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.plot(mlearn.)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "\n",
                "from surpbayes.meta_bayes.task import Task\n",
                "from surpbayes.proba import ProbaMap\n",
                "from surpbayes.bayes import pacbayes_minimize\n",
                "from surpbayes.types import ProbaParam, ProbaParams\n",
                "\n",
                "from surpbayes.misc import par_eval, blab\n",
                "\n",
                "def test_eval_task(meta_param:ProbaParam, test_task:Task, proba_map:ProbaMap, n_test:int, hyperparams:dict):\n",
                "    \"\"\"Evaluate a test task at meta_param\n",
                "    \n",
                "    The task training is performed from scratch (empty accu),\n",
                "    starting from meta_param prior. This prevents potential bias due\n",
                "    to more accurate solutions being found after some iterations.\n",
                "    \"\"\"\n",
                "    opt_res = pacbayes_minimize(\n",
                "        fun=test_task.score,\n",
                "        proba_map=proba_map,\n",
                "        prior_param=meta_param,\n",
                "        post_param=meta_param,\n",
                "        temperature=test_task.temp,\n",
                "        prev_eval=None,\n",
                "        vectorized=test_task.vectorized,\n",
                "        parallel=test_task.parallel,\n",
                "        **hyperparams,\n",
                "    )\n",
                "    post_param = opt_res.opti_param\n",
                "    \n",
                "    post = proba_map(post_param)\n",
                "    if test_task.vectorized:\n",
                "        mean_score = np.mean(test_task.score(post(n_test)))\n",
                "    else:\n",
                "        mean_score = np.mean(par_eval(test_task.score, post(n_test), parallel=test_task.parallel))\n",
                "\n",
                "    return mean_score + test_task.temp * proba_map.kl(post_param, meta_param)\n",
                "\n",
                "def eval_meta_param(meta_param:ProbaParam, test_tasks:list[Task], proba_map:ProbaMap, n_test:int, hyperparams, silent:bool=False):\n",
                "    \"\"\"Evaluate a meta_param on a list of test_tasks\"\"\"\n",
                "    accu = np.zeros(len(test_tasks))\n",
                "    for i, task in enumerate(test_tasks):\n",
                "        perf = test_eval_task(meta_param=meta_param, test_task=task, proba_map=proba_map, n_test=n_test, hyperparams=hyperparams)\n",
                "        blab(silent, f\"Task {i}: {perf}\")\n",
                "        accu[i] = perf\n",
                "    return accu\n",
                "\n",
                "def eval_meta_hist(meta_params:ProbaParams, test_tasks:list[Task], proba_map:ProbaMap, n_test:int=100, hyperparams:dict={}, silent:bool=False):\n",
                "    \"\"\"Evaluate a succession of meta_params\"\"\"\n",
                "\n",
                "    accu = np.zeros((len(meta_params), len(test_tasks)))\n",
                "    for j, meta_param in enumerate(meta_params):\n",
                "        blab(silent, f\"Starting meta_param {j}\")\n",
                "        accu[j] = eval_meta_param(meta_param=meta_param, test_tasks=test_tasks, proba_map=proba_map, n_test= n_test,hyperparams=hyperparams, silent=silent)\n",
                "    return accu\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from surpbayes.meta_bayes.test_assess import eval_meta_hist"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "mlearn.hist_meta.meta_params()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "res = eval_meta_hist(mlearn.hist_meta.meta_params()[::2], test_tasks, proba_map = proba_map, hyperparams = {\"per_step\": 50, \"chain_length\":1, \"silent\":True})"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import matplotlib.pyplot as plt\n",
                "for i in range(res.shape[1]):\n",
                "    plt.plot(res[:, i])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "mlearn.meta_learn(epochs=20, eta=20.0, kl_max=1.0)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Launch training (either through meta_learn or meta_learn_batch. meta_learn_batch is more stable)\n",
                "# mlearn.hyperparams[\"chain_length\"] = 2\n",
                "# mlearn.hyperparams[\"per_step\"] = 0\n",
                "# mlearn.converged = False\n",
                "mlearn.meta_learn_batch(epochs=10, eta=200.0, kl_max=0.4, silent=False, kl_tol=10**-7)\n",
                "# mlearn.hyperparams[\"per_step\"] = 10\n",
                "# mlearn.meta_learn_batch(epochs=40, eta=40.0, kl_max=0.5, silent=False, kl_tol=10**-5)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "proba_map(mlearn.prior_param)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "x0"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "mlearn.save(\"my_learning_env\", overwrite=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from surpbayes import load_accu\n",
                "from surpbayes.meta_bayes.task import load_task\n",
                "\n",
                "task = load_task(\"my_learning_env/tasks/task_0/\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "task.accu_sample_val.ts()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "[\n",
                "    proba_map.kl(par2, par1)\n",
                "    for par2, par1 in zip(\n",
                "        mlearn.hist_meta.meta_params(20)[1:], mlearn.hist_meta.meta_params(20)\n",
                "    )\n",
                "]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "mlearn.list_task[0].accu_sample_val.n_filled"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "proba_map(mlearn.prior_param).devs"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from surpbayes.proba import FactCovGaussianMap"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "help(FactCovGaussianMap)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "from surpbayes.proba import FactCovGaussianMap"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "## Double check implementation of g function\n",
                "d = 4\n",
                "# proba_map = TensorizedGaussianMap(d)\n",
                "# proba_map = BlockDiagGaussMap([[0,2, 1], [ 3]])\n",
                "proba_map = FactCovGaussianMap(d)\n",
                "\n",
                "param0 = np.random.normal(0, 1, proba_map.proba_param_shape)\n",
                "param1 = np.random.normal(0, 1, proba_map.proba_param_shape)\n",
                "param2 = np.random.normal(0, 1, proba_map.proba_param_shape)\n",
                "\n",
                "proba0 = proba_map(param0)\n",
                "proba1 = proba_map(param1)\n",
                "proba2 = proba_map(param2)\n",
                "\n",
                "xs = proba0(1000)\n",
                "\n",
                "ldens_0 = proba0.log_dens(xs)  # = h(x) + T(x).theta - g(theta)\n",
                "ldens_1 = proba1.log_dens(xs)\n",
                "ldens_2 = proba2.log_dens(xs)\n",
                "\n",
                "tpar0 = proba_map.param_to_T(param0)\n",
                "tpar1 = proba_map.param_to_T(param1)\n",
                "tpar2 = proba_map.param_to_T(param2)\n",
                "\n",
                "ts = proba_map.T(xs)\n",
                "\n",
                "ldens_t_0 = (ts * tpar0).sum(-1) - proba_map.g(tpar0)  # T(x). theta - g(theta)\n",
                "ldens_t_1 = (ts * tpar1).sum(-1) - proba_map.g(tpar1)\n",
                "ldens_t_2 = (ts * tpar2).sum(-1) - proba_map.g(tpar2)\n",
                "\n",
                "print(np.mean(np.abs(ldens_0 - ldens_t_0 - ldens_1 + ldens_t_1)))\n",
                "print(np.mean(np.abs(ldens_0 - ldens_t_0 - ldens_2 + ldens_t_2)))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "scrolled": false
            },
            "outputs": [],
            "source": [
                "# proba_map = BlockDiagGaussMap([[0,2, 1], [ 3]])\n",
                "proba_map = FactCovGaussianMap(4)\n",
                "epsilon = 10 ** (-7)\n",
                "\n",
                "accu = np.zeros(100)\n",
                "for i in range(100):\n",
                "    param0 = np.random.normal(0, 1, proba_map.proba_param_shape)\n",
                "    tpar0 = proba_map.param_to_T(param0)\n",
                "\n",
                "    delta = epsilon * np.random.normal(0, 1, proba_map.t_shape)\n",
                "    #     delta[:4] = 0.0\n",
                "\n",
                "    g0 = proba_map.g(tpar0)\n",
                "    g1 = proba_map.g(tpar0 + delta)\n",
                "\n",
                "    res = (g1 - g0) / np.sum(delta * proba_map.grad_g(tpar0))\n",
                "\n",
                "    if res < 0:\n",
                "        print(f\"Sign problem: {res}\")\n",
                "        proba = proba_map(proba_map.T_to_param(tpar0))\n",
                "        print(np.max(proba.vals) / np.min(proba.vals))\n",
                "        proba = proba_map(proba_map.T_to_param(tpar0 + delta))\n",
                "        print(np.max(proba.vals) / np.min(proba.vals))\n",
                "        print()\n",
                "    elif np.log(res) > 0.1:\n",
                "        print(f\"Unstable: {np.log(res)}\")\n",
                "        proba = proba_map(proba_map.T_to_param(tpar0))\n",
                "        print(np.max(proba.vals) / np.min(proba.vals))\n",
                "        proba = proba_map(proba_map.T_to_param(tpar0 + delta))\n",
                "        print(np.max(proba.vals) / np.min(proba.vals))\n",
                "        print()\n",
                "    #     else:\n",
                "    #         print(\"Stable\")\n",
                "    #         proba = proba_map(proba_map.T_to_param(tpar0))\n",
                "    #         print(np.max(proba.devs)/np.min(proba.devs))\n",
                "    #         proba = proba_map(proba_map.T_to_param(tpar0 + delta))\n",
                "    #         print(np.max(proba.devs)/np.min(proba.devs))\n",
                "    #         print()\n",
                "\n",
                "    accu[i] = res\n",
                "\n",
                "# print(np.max(np.abs(np.log(accu))))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "tpar = np.array(\n",
                "    [\n",
                "        -1156.27631014,\n",
                "        -796.41509995,\n",
                "        8591.1302817,\n",
                "        3995.3597264,\n",
                "        167.82754323,\n",
                "        80.06845902,\n",
                "        9251.03475923,\n",
                "        2002.14959828,\n",
                "        115.59336995,\n",
                "        -1245.32377343,\n",
                "        -579.39681635,\n",
                "        -857.58412415,\n",
                "        -399.04037178,\n",
                "        4302.99413866,\n",
                "    ]\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "proba_map(proba_map.T_to_param(tpar))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.plot([proba_map(par).devs[1] for par in mlearn.hist_meta.meta_params()])\n",
                "plt.yscale(\"log\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "np.cov(x_middles.T)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import matplotlib.pyplot as plt\n",
                "\n",
                "plt.plot(mlearn.hist_meta.meta_scores(20))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "proba_map(mlearn.prior_param).cov"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "proba_map(mlearn.hist_meta.meta_params(1)[0]).means"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "np.cov(x_middles.T)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "x_middles.mean(0)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import matplotlib.pyplot as plt\n",
                "\n",
                "print(\n",
                "    f\"Center recovery error: {(mlearn.prior_param[0] - x_middles.mean(0))/ x_middles.mean(0)}\"\n",
                ")\n",
                "\n",
                "plt.plot(mlearn.hist_meta.meta_params(1000)[:, 0, 0], label=r\"$\\theta_0$\")\n",
                "plt.plot(mlearn.hist_meta.meta_params(1000)[:, 0, 1], label=r\"$\\theta_1$\")\n",
                "plt.legend()\n",
                "plt.title(\"Evolution of prior mean\")\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Covariance case"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Choose dimension/Number of tasks\n",
                "d = 4\n",
                "true_dim = 1\n",
                "n_tasks = 20\n",
                "\n",
                "# Generate tasks\n",
                "def make_score(x):\n",
                "    def score(xs):\n",
                "        return ((x - xs) ** 2).sum(-1)\n",
                "\n",
                "    return score\n",
                "\n",
                "\n",
                "matrix = np.random.normal(0, 1, (true_dim, d))\n",
                "x_middles = np.random.normal(0, 1.0, (n_tasks, true_dim)) @ matrix + np.random.normal(\n",
                "    0, 0.01, (n_tasks, d)\n",
                ")\n",
                "\n",
                "list_task = [\n",
                "    Task(make_score(x_mid), temperature=0.1, vectorized=True) for x_mid in x_middles\n",
                "]\n",
                "\n",
                "# Define distribution family\n",
                "proba_map = GaussianMap(d)\n",
                "\n",
                "# Define Meta Learning Environnement\n",
                "mlearn = MetaLearningEnv(\n",
                "    proba_map,\n",
                "    list_task=list_task,\n",
                "    per_step=25,\n",
                "    chain_length=1,\n",
                "    n_estim_weights=50,\n",
                "    kl_max=100.0,\n",
                "    silent=True,\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Launch training (either through meta_learn or meta_learn_batch. meta_learn_batch is more stable)\n",
                "mlearn.meta_learn_batch(epochs=20, eta=2.0, kl_max=1.0, silent=True, kl_tol=10**-5)\n",
                "mlearn.meta_learn_batch(epochs=20, eta=1.0, kl_max=1.0, silent=True, kl_tol=10**-5)\n",
                "mlearn.meta_learn_batch(epochs=20, eta=0.5, kl_max=1.0, silent=True, kl_tol=10**-5)\n",
                "mlearn.meta_learn_batch(epochs=20, eta=0.25, kl_max=1.0, silent=True, kl_tol=10**-5)\n",
                "mlearn.meta_learn_batch(epochs=20, eta=0.1, kl_max=1.0, silent=True, kl_tol=10**-5)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.plot(mlearn.hist_meta.meta_scores(100))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "mlearn.proba_map(mlearn.prior_param)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "x_middles.mean(0)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "np.cov(x_middles.T) / mlearn.proba_map(mlearn.prior_param).cov"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Future improvements\n",
                "\n",
                "### Sample size for the inner task\n",
                "\n",
                "In the current implementation, the inner algorithm evaluates a fixed number of parameters generated from the current posterior. This might slow down the algorithm significantly, as once the space has been thoroughly explored, it is not necessary to evaluate many new points (at least not as much as during the early stages). The number of new points evaluated should be estimated depending on how well the current sample explores the posterior.\n",
                "\n",
                "On the same lines, the positions of the samples evaluated could be optimized.\n",
                "\n",
                "### Step size adaptation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "spbb-env",
            "language": "python",
            "name": "spbb-env"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.19"
        },
        "vscode": {
            "interpreter": {
                "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}